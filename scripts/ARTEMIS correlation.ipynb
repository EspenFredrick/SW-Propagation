{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ARTEMIS Correlation Calculator\n",
    "---\n",
    "Correlate any near-Earth data with ARTEMIS around the Moon\n",
    "Choose from THEMIS or MMS in-situ measurements, or OMNI data projected to the bow shock"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import csv\n",
    "\n",
    "# Pyspedas libraries\n",
    "import pyspedas\n",
    "from pytplot import del_data, get_data, get_timespan, store_data, tplot_options, tplot_names, tplot, tplot_math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def import_events(path, satellite): # Function to import the data from a satellite to compare with Artemis: either OMNI, THEMIS, or MMS\n",
    "    probe = [] # Initialize probe ID array\n",
    "    bowshock_times = [] # Initialize start and stop time array for 'satellite'\n",
    "    lunar_times = [] # Initialize start and stop time array for ARTEMIS\n",
    "\n",
    "    with open(path, newline='') as events:\n",
    "        rows = csv.reader(events)\n",
    "        next(rows)\n",
    "        for r in rows:\n",
    "            bowshock_times.append([(dt.datetime.strptime(r[0], '%Y-%m-%dT%H:%M:%S.%fZ')+dt.timedelta(minutes=30)).strftime('%Y-%m-%d/%H:%M:%S'), (dt.datetime.strptime(r[1], '%Y-%m-%dT%H:%M:%S.%fZ')).strftime('%Y-%m-%d/%H:%M:%S')])\n",
    "            lunar_times.append([(dt.datetime.strptime(r[0], '%Y-%m-%dT%H:%M:%S.%fZ')).strftime('%Y-%m-%d/%H:%M:%S'), (dt.datetime.strptime(r[1], '%Y-%m-%dT%H:%M:%S.%fZ')).strftime('%Y-%m-%d/%H:%M:%S')])\n",
    "            if satellite == 'mms':\n",
    "                probe.append(r[2])\n",
    "            elif satellite == 'themis':\n",
    "                probe.append(str(r[3]))\n",
    "            elif satellite == 'omni':\n",
    "                probe.append('o')\n",
    "\n",
    "        if satellite == 'omni':\n",
    "            keys = np.arange(len(probe)) # Create dictionary keys 0...n equal to the number of input events\n",
    "            types = ('time', 'bx', 'by', 'bz', 'vx', 'vy', 'vz', 'n', 'T') # Keys for the sub-dictionary in each event\n",
    "            data = dict((i, dict.fromkeys(types)) for i in keys) # Create the 'data' dictionary\n",
    "            for i in keys: # Iterate through every event\n",
    "                import_data = pyspedas.omni.data(trange=bowshock_times[i], datatype='1min', level='hro2', time_clip=True) # Import the tplot variable for the ith event\n",
    "                varnames = ['BX_GSE', 'BY_GSE', 'BZ_GSE', 'Vx', 'Vy', 'Vz', 'proton_density', 'T']\n",
    "                for p in varnames:\n",
    "                    tplot_math.interp_nan(p)\n",
    "                products = [get_data('IMF')[0], get_data('BX_GSE')[1], get_data('BY_GSE')[1], get_data('BZ_GSE')[1], get_data('Vx')[1], get_data('Vy')[1], get_data('Vz')[1], get_data('proton_density')[1], get_data('T')[1]] # Each event in the 'data' dictionary will consist of these products\n",
    "                for j, k in enumerate(types): # Now go through the keys of the sub-dictionary\n",
    "                    data[i][k] = products[j] # For the first sub-dict key, set that equal to the first product (and so on)...\n",
    "\n",
    "                data[i]['time'] = data[i]['time'].astype('object')\n",
    "                for n in range(len(data[i]['time'])):\n",
    "                    data[i]['time'][n] = dt.datetime.utcfromtimestamp(data[i]['time'][n])\n",
    "\n",
    "\n",
    "        if satellite == 'themis':\n",
    "            keys = np.arange(len(probe)) # Create dictionary keys 0...n equal to the number of input events\n",
    "            fgm_types = ('time', 'bx', 'by', 'bz') # Keys for the sub-dictionary in each event\n",
    "            esa_types = ('time', 'vx', 'vy', 'vz', 'n', 'T')\n",
    "            themis_fgm_data = dict((i, dict.fromkeys(fgm_types)) for i in keys) # Create the 'fgm_data' dictionary\n",
    "            themis_esa_data = dict((i, dict.fromkeys(esa_types)) for i in keys) # Create the 'esa_data' dictionary\n",
    "            for i in keys:\n",
    "                themis_fgm_import = pyspedas.themis.fgm(trange=bowshock_times[i], probe=probe[i], time_clip=True, varnames='th'+probe[i]+'_fgs_gse')\n",
    "                themis_esa_import = pyspedas.themis.esa(trange=bowshock_times[i], probe=probe[i], time_clip=True, varnames=['th'+probe[i]+'_peif_density', 'th'+probe[i]+'_peif_avgtemp', 'th'+probe[i]+'_peif_velocity_gse'])\n",
    "                fgm_products = [get_data('th'+probe[i]+'_fgs_gse')[0], get_data('th'+probe[i]+'_fgs_gse')[1][:,0], get_data('th'+probe[i]+'_fgs_gse')[1][:,1], get_data('th'+probe[i]+'_fgs_gse')[1][:,2]]\n",
    "                esa_products = [get_data('th'+probe[i]+'_peif_velocity_gse')[0], get_data('th'+probe[i]+'_peif_velocity_gse')[1][:,0], get_data('th'+probe[i]+'_peif_velocity_gse')[1][:,1], get_data('th'+probe[i]+'_peif_velocity_gse')[1][:,2], get_data('th'+probe[i]+'_peif_density')[1], get_data('th'+probe[i]+'_peif_avgtemp')[1]]\n",
    "                for j, k in enumerate(fgm_types):\n",
    "                    themis_fgm_data[i][k] = fgm_products[j]\n",
    "                for m, n in enumerate(esa_types):\n",
    "                    themis_esa_data[i][n] = esa_products[m]\n",
    "\n",
    "        keys = np.arange(len(probe)) # Create dictionary keys 0...n equal to the number of input events\n",
    "        fgm_types = ('time', 'bx', 'by', 'bz') # Keys for the sub-dictionary in each event\n",
    "        esa_types = ('time', 'vx', 'vy', 'vz', 'n', 'T')\n",
    "        artemis_fgm_data = dict((i, dict.fromkeys(fgm_types)) for i in keys) # Create the 'fgm_data' dictionary\n",
    "        artemis_esa_data = dict((i, dict.fromkeys(esa_types)) for i in keys) # Create the 'esa_data' dictionary\n",
    "        for i in keys:\n",
    "            artemis_fgm_import = pyspedas.themis.fgm(trange=lunar_times[i], probe='b', time_clip=True, varnames='thb_fgs_gse')\n",
    "            artemis_esa_import = pyspedas.themis.esa(trange=lunar_times[i], probe='b', time_clip=True, varnames=['thb_peif_density', 'thb_peif_avgtemp', 'thb_peif_velocity_gse'])\n",
    "            fgm_products = [get_data('thb_fgs_gse')[0], get_data('thb_fgs_gse')[1][:,0], get_data('thb_fgs_gse')[1][:,1], get_data('thb_fgs_gse')[1][:,2]]\n",
    "            esa_products = [get_data('thb_peif_velocity_gse')[0], get_data('thb_peif_velocity_gse')[1][:,0], get_data('thb_peif_velocity_gse')[1][:,1], get_data('thb_peif_velocity_gse')[1][:,2], get_data('thb_peif_density')[1], get_data('thb_peif_avgtemp')[1]]\n",
    "            for j, k in enumerate(fgm_types):\n",
    "                artemis_fgm_data[i][k] = fgm_products[j]\n",
    "            for j, k in enumerate(esa_types):\n",
    "                artemis_esa_data[i][k] = esa_products[j]\n",
    "\n",
    "            artemis_fgm_data[i]['time'] = artemis_fgm_data[i]['time'].astype('object')\n",
    "            artemis_esa_data[i]['time'] = artemis_esa_data[i]['time'].astype('object')\n",
    "            for n in range(len(artemis_fgm_data[i]['time'])):\n",
    "                artemis_fgm_data[i]['time'][n] = dt.datetime.utcfromtimestamp(artemis_fgm_data[i]['time'][n])\n",
    "            for n in range(len(artemis_esa_data[i]['time'])):\n",
    "                artemis_esa_data[i]['time'][n] = dt.datetime.utcfromtimestamp(artemis_esa_data[i]['time'][n])\n",
    "\n",
    "\n",
    "\n",
    "    if satellite == 'omni':\n",
    "        return data, artemis_fgm_data, artemis_esa_data\n",
    "    if satellite == 'themis':\n",
    "        return themis_fgm_data, themis_esa_data, artemis_fgm_data, artemis_esa_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "omni, a_fgm, a_esa = import_events('../eventlist/eventlist.csv', 'omni')\n",
    "#t_fgm, t_esa, a_fgm, a_esa = import_events('../eventlist/eventlist.csv', 'themis')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next cell defines the averaging function for reducing ARTEMIS and THEMIS to a 1-minute cadence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def average(times, data):\n",
    "    minute = times[0].minute # Set the current first minute of the data set\n",
    "    timeAvgs = [] # Create empty array to store the time-averaged values\n",
    "    avgArr = [] # Create empty storage array\n",
    "    timeStep = [] # Create empty time step array\n",
    "    for i in range(len(times)): # Index the values\n",
    "        if times[i].minute == minute: # If the time of the next value equals the one set for the minute\n",
    "            avgArr.append(data[i]) # Append this to the storage array\n",
    "        elif times[i].minute == minute + 1: # If the time of the next value equals the next minute\n",
    "            #print(avgArr)\n",
    "            timeAvgs.append(np.average(avgArr)) # Average the storage array and append it to the time-averaged value array\n",
    "            #print(np.average(avgArr))\n",
    "            timeStep.append(dt.datetime(times[i-1].year, times[i-1].month, times[i-1].day, times[i-1].hour, times[i-1].minute, 00)) # Create a timestamp for the previous minute centered at 0s to line up with the orbit timestamps\n",
    "            minute= times[i].minute # Set the new current minute to start averaging over\n",
    "            avgArr = [] # Clear the storage array\n",
    "        elif times[i].minute == minute - 59: # This is for rollover: when the next minute is 0\n",
    "            #print(avgArr)\n",
    "            timeAvgs.append(np.average(avgArr))\n",
    "            #print(np.average(avgArr))\n",
    "            timeStep.append(dt.datetime(times[i-1].year, times[i-1].month, times[i-1].day, times[i-1].hour, times[i-1].minute, 00))\n",
    "            minute = times[i].minute\n",
    "            avgArr = []\n",
    "    return timeStep, timeAvgs # Return the time-averaged array and the timestamp array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fgm_to_avg = ('bx', 'by', 'bz')\n",
    "\n",
    "for i in a_fgm:\n",
    "    for j in fgm_to_avg:\n",
    "        time_storeage, a_fgm[i][j] = average(a_fgm[i]['time'], a_fgm[i][j])\n",
    "    a_fgm[i]['time'] = time_storeage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}